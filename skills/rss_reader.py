#!/usr/bin/env python3
"""
RSS Reader Skill
Fetches and parses RSS feeds from configured sources.
"""
import feedparser
import random
import requests
from datetime import datetime
import time

from core.utils_security import load_config
SEC_CONFIG = load_config()

# é¢„å®šä¹‰çš„ RSS æºåˆ—è¡¨ (Tech & AI Focused) - Fallback
DEFAULT_RSS_FEEDS = {
    # AI & Research
    "OpenAI Blog": "https://openai.com/blog/rss.xml",
    "Anthropic Research": "https://www.anthropic.com/feed", 
    "Hugging Face Blog": "https://huggingface.co/blog/feed.xml",
    "DeepMind Blog": "https://deepmind.google/blog/rss.xml",
    
    # Tech News & Engineering
    "Vercel Blog": "https://vercel.com/atom",
    "Stripe Engineering": "https://stripe.com/blog/engineering/rss",
    "Prisma Blog": "https://www.prisma.io/blog/rss.xml",
    "Supabase Blog": "https://supabase.com/blog/rss.xml",
    
    # Tech News Media (CN)
    "å°‘æ•°æ´¾": "https://sspai.com/feed",
    "çˆ±èŒƒå„¿": "https://www.ifanr.com/feed",
    "é’›åª’ä½“": "https://www.tmtpost.com/feed",
    "æœºæ ¸ GCORES": "https://www.gcores.com/rss",
    "V2EX": "https://www.v2ex.com/feed/tab/tech.xml",

    # Tech News Media (JP)
    "ITmedia News": "https://rss.itmedia.co.jp/rss/2.0/news_bursts.xml",
    "PC Watch": "https://pc.watch.impress.co.jp/data/rss/1.0/pcw/feed.rdf",
    "GIZMODO Japan": "https://www.gizmodo.jp/index.xml",

    # Tech News Media (EN)
    "TechCrunch": "https://techcrunch.com/feed/",
    "The Verge": "https://www.theverge.com/rss/tech/index.xml",
    "Ars Technica": "https://feeds.arstechnica.com/arstechnica/technology-lab",
    "Wired": "https://www.wired.com/feed/rss",
}

RSS_FEEDS = SEC_CONFIG.get("social", {}).get("rss_feeds", DEFAULT_RSS_FEEDS)

def get_random_rss_item():
    """éšæœºä» RSS åˆ—è¡¨ä¸­æŠ“å–ä¸€ç¯‡æ–‡ç« """
    
    # éšæœºé€‰æ‹© 3 ä¸ªæºè¿›è¡Œå°è¯•ï¼Œé¿å…æ¯æ¬¡éƒ½éå†æ‰€æœ‰å¯¼è‡´å¤ªæ…¢
    feed_names = list(RSS_FEEDS.keys())
    random.shuffle(feed_names)
    selected_feeds = feed_names[:3]
    
    candidates = []
    
    for name in selected_feeds:
        url = RSS_FEEDS[name]
        try:
            print(f"  ğŸ“¡ Fetching RSS: {name}...")
            # Set a timeout to prevent hanging
            feed = feedparser.parse(url)
            
            if feed.entries:
                # åªå–æœ€è¿‘çš„ 3 ç¯‡æ–‡ç« ï¼Œä¿è¯æ—¶æ•ˆæ€§
                entries = feed.entries[:3]
                entry = random.choice(entries)
                
                # æå–å¿…è¦ä¿¡æ¯
                item = {
                    "source": name,
                    "title": entry.get('title', 'Unknown Title'),
                    "link": entry.get('link', ''),
                    "summary": entry.get('summary', entry.get('description', ''))[:300], # æˆªæ–­
                    "date": entry.get('published', entry.get('updated', ''))
                }
                
                # ç®€å•çš„æœ‰æ•ˆæ€§æ£€æŸ¥
                if item['link'] and item['title']:
                    candidates.append(item)
                    
        except Exception as e:
            print(f"âš ï¸ Error fetching {name}: {e}")
            continue
    
    if candidates:
        return random.choice(candidates)
        
    return None

if __name__ == "__main__":
    # Test script
    item = get_random_rss_item()
    if item:
        print(f"âœ… Selected: [{item['source']}] {item['title']}\n{item['link']}")
    else:
        print("âŒ No valid RSS items found.")
